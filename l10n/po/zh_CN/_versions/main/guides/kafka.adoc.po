# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR Free Software Foundation, Inc.
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2021-07-11 01:23+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. This guide is maintained in the main Quarkus repository
#. and pull requests should be submitted there:
#. https://github.com/quarkusio/quarkus/tree/main/docs/src/main/asciidoc
#. type: Title =
#: upstream/_versions/main/guides/kafka.adoc:6
#, no-wrap
msgid "Apache Kafka Reference Guide"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:16
msgid "This reference guide demonstrates how your Quarkus application can utilize SmallRye Reactive Messaging to interact with Apache Kafka."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:17
#, no-wrap
msgid "Introduction"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:22
msgid "https://kafka.apache.org[Apache Kafka] is a popular open-source distributed event streaming platform.  It is used commonly for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.  Similar to a message queue, or an enterprise messaging platform, it lets you:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:24
#, no-wrap
msgid "*publish* (write) and *subscribe* to (read) streams of events, called _records_.\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:25
#, no-wrap
msgid "*store* streams of records durably and reliably inside _topics_.\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:26
#, no-wrap
msgid "*process* streams of records as they occur or retrospectively.\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:28
msgid "And all this functionality is provided in a distributed, highly scalable, elastic, fault-tolerant, and secure manner."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:29
#, no-wrap
msgid "Quarkus Extension for Apache Kafka"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:33
msgid "Quarkus provides support for Apache Kafka through https://smallrye.io/smallrye-reactive-messaging/[Smallrye Reactive Messaging] framework.  Based on Eclipse MicroProfile Reactive Messaging specification 2.0, it proposes a flexible programming model bridging CDI and event-driven."
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:38
msgid "This guide provides an in-depth look on Apache Kafka and Smallrye Reactive Messaging framework.  For a quick start take a look at xref:kafka-reactive-getting-started.adoc[Getting Started to SmallRye Reactive Messaging with Apache Kafka]."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:41
msgid "You can add the `smallrye-reactive-messaging-kafka` extensions to your project by running the following command in your project base directory:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:45
#, no-wrap
msgid "./mvnw quarkus:add-extension -Dextensions=\"smallrye-reactive-messaging-kafka\"\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:48
msgid "This will add the following to your `pom.xml`:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:55
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-smallrye-reactive-messaging-kafka</artifactId>\n"
"</dependency>\n"
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:57
#, no-wrap
msgid "Configuring Smallrye Kafka Connector"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:60
msgid "Because Smallrye Reactive Messaging framework supports different messaging backends like Apache Kafka, AMQP, Apache Camel, JMS, MQTT, etc., it employs a generic vocabulary:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:62
msgid "Applications send and receive *messages*. A message wraps a _payload_ and can be extended with some _metadata_. With the Kafka connector, a _message_ corresponds to a Kafka _record_."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:63
msgid "Messages transit on *channels*. Application components connect to channels to publish and consume messages. The Kafka connector maps _channels_ to Kafka _topics_."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:64
msgid "Channels are connected to message backends using *connectors*. Connectors are configured to map incoming messages to a specific channel (consumed by the application) and collect outgoing messages sent to a specific channel. Each connector is dedicated to a specific messaging technology. For example, the connector dealing with Kafka is named `smallrye-kafka`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:66
msgid "A minimal configuration for the Kafka connector with an incoming channel looks like the following:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:71
#, no-wrap
msgid ""
"%prod.kafka.bootstrap.servers=kafka:9092 <1>\n"
"mp.messaging.incoming.prices.connector=smallrye-kafka <2>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:76
msgid "Configure the broker location for the production profile. You can configure it globally or per channel using `mp.messaging.incoming.$channel.bootstrap.servers` property.  In dev mode and when running tests, link:kafka-dev-services.adoc[Dev Services for Kafka] automatically starts a Kafka broker.  When not provided this property defaults to `localhost:9092`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:77
msgid "Configure the connector to manage the prices channel. By default the topic name is same as the channel name. You can configure the topic attribute to override it."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:79
msgid "The `%prod` prefix indicates that the property is only used when the application runs in prod mode (so not in dev or test). Refer to the xref:config-reference.adoc#profiles[Profile documentation] for further details."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:80
#, no-wrap
msgid "Receiving messages from Kafka"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:83
msgid "Continuing from the previous minimal configuration, your Quarkus application can receive message payload directly:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:87
#, no-wrap
msgid "import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:89
#: upstream/_versions/main/guides/kafka.adoc:834
#: upstream/_versions/main/guides/kafka.adoc:881
#: upstream/_versions/main/guides/kafka.adoc:904
#: upstream/_versions/main/guides/kafka.adoc:1034
#, no-wrap
msgid "import javax.enterprise.context.ApplicationScoped;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:92
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class PriceConsumer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:97
#, no-wrap
msgid ""
"    @Incoming(\"prices\")\n"
"    public void consume(double price) {\n"
"        // process your price.\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:99
#: upstream/_versions/main/guides/kafka.adoc:243
#: upstream/_versions/main/guides/kafka.adoc:506
#: upstream/_versions/main/guides/kafka.adoc:531
#: upstream/_versions/main/guides/kafka.adoc:591
#: upstream/_versions/main/guides/kafka.adoc:894
#: upstream/_versions/main/guides/kafka.adoc:922
#: upstream/_versions/main/guides/kafka.adoc:996
#: upstream/_versions/main/guides/kafka.adoc:1053
#: upstream/_versions/main/guides/kafka.adoc:1412
#, no-wrap
msgid "}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:102
msgid "There are several other ways your application can consume incoming messages:"
msgstr ""

#. type: Block title
#: upstream/_versions/main/guides/kafka.adoc:103
#, no-wrap
msgid "Message"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:115
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public CompletionStage<Void> consume(Message<Double> msg) {\n"
"    // access record metadata\n"
"    var metadata = msg.getMetadata(IncomingKafkaRecordMetadata.class).orElseThrow();\n"
"    // process the message payload.\n"
"    double price = msg.getPayload();\n"
"    // Acknowledge the incoming message (commit the offset)\n"
"    return msg.ack();\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:119
msgid "`Message` type lets the consuming method to access the incoming message metadata and handle the acknowledgment manually.  We'll explore different acknowledgment strategies in <<commit-strategies>>."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:121
msgid "If you want to access the Kafka record objects directly, use:"
msgstr ""

#. type: Block title
#: upstream/_versions/main/guides/kafka.adoc:122
#, no-wrap
msgid "ConsumerRecord"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:133
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public void consume(ConsumerRecord<String, Double> record) {\n"
"    String key = record.key(); // Can be `null` if the incoming record has no key\n"
"    String value = record.value(); // Can be `null` if the incoming record has no value\n"
"    String topic = record.topic();\n"
"    int partition = record.partition();\n"
"    // ...\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:137
msgid "`ConsumerRecord` is provided by the underlying Kafka client and can be injected directly to the consumer method.  Another simpler approach consists in using `Record`:"
msgstr ""

#. type: Block title
#: upstream/_versions/main/guides/kafka.adoc:138
#, no-wrap
msgid "Record"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:146
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public void consume(Record<String, Double> record) {\n"
"    String key = record.key(); // Can be `null` if the incoming record has no key\n"
"    String value = record.value(); // Can be `null` if the incoming record has no value\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:149
msgid "`Record` is a simple wrapper around key and payload of the incoming Kafka record."
msgstr ""

#. type: Block title
#: upstream/_versions/main/guides/kafka.adoc:150
#, no-wrap
msgid "@Channel"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:153
msgid "Alternatively, your application can inject a `Multi` in your bean and subscribe to its events as the following example:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:158
#, no-wrap
msgid ""
"import io.smallrye.mutiny.Multi;\n"
"import io.smallrye.reactive.messaging.annotations.Channel;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:165
#, no-wrap
msgid ""
"import javax.inject.Inject;\n"
"import javax.ws.rs.GET;\n"
"import javax.ws.rs.Path;\n"
"import javax.ws.rs.Produces;\n"
"import javax.ws.rs.core.MediaType;\n"
"import org.jboss.resteasy.annotations.SseElementType;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:168
#: upstream/_versions/main/guides/kafka.adoc:668
#: upstream/_versions/main/guides/kafka.adoc:711
#: upstream/_versions/main/guides/kafka.adoc:747
#, no-wrap
msgid ""
"@Path(\"/prices\")\n"
"public class PriceResource {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:171
#, no-wrap
msgid ""
"    @Inject\n"
"    @Channel(\"prices\") Multi<Double> prices;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:180
#, no-wrap
msgid ""
"    @GET\n"
"    @Path(\"/prices\")\n"
"    @Produces(MediaType.SERVER_SENT_EVENTS)\n"
"    @SseElementType(\"text/plain\")\n"
"    public Multi<Double> stream() {\n"
"        return prices;\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:184
msgid "This is a good example of how to integrate a Kafka consumer with another downstream, in this example exposing it as a Server-Sent Events endpoint."
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:190
msgid "When consuming messages with `@Channel`, the application code is responsible for the subscription.  In the example above RESTEasy endpoint handles that for you."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:193
msgid "Following types can be injected as channels:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:197
#, no-wrap
msgid "@Inject @Channel(\"prices\") Multi<Double> streamOfPayloads;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:199
#, no-wrap
msgid "@Inject @Channel(\"prices\") Multi<Message<Double>> streamOfMessages;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:201
#, no-wrap
msgid "@Inject @Channel(\"prices\") Publisher<Double> publisherOfPayloads;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:203
#, no-wrap
msgid "@Inject @Channel(\"prices\") Publisher<Message<Double>> publisherOfMessages;\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:208
msgid "As with the previous `Message` example, if your injected channel receives payloads (`Multi<T>`), it acknowledges the message automatically, and support multiple subscribers.  If you injected channel receives Message (`Multi<Message<T>>`), you will be responsible for the acknowledgment and broadcasting.  We will explore sending broadcast messages in <<broadcasting-messages-on-multiple-consumers>>."
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:213
msgid "Injecting `@Channel(\"prices\")` or having `@Incoming(\"prices\")` does not automatically configure the application to consume messages from Kafka.  You need to configure an inbound connector with `mp.messageing.incoming.prices...` or have an `@Outgoing(\"prices\")` somewhere in your application (meaning a method generating messages transiting on the channel \"prices\")."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:215
#, no-wrap
msgid "Blocking processing"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:219
msgid "You often need to combine Reactive Messaging with blocking processing such as database interactions.  For this, you need to use the `@Blocking` annotation indicating that the processing is _blocking_ and should not be run on the caller thread."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:221
msgid "For example, The following code illustrates how you can store incoming payloads to a database using Hibernate with Panache:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:226
#, no-wrap
msgid ""
"import io.smallrye.reactive.messaging.annotations.Blocking;\n"
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:229
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.transaction.Transactional;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:232
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class PriceStorage {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:241
#, no-wrap
msgid ""
"    @Incoming(\"prices\")\n"
"    @Blocking\n"
"    @Transactional\n"
"    public void store(int priceInUsd) {\n"
"        Price price = new Price();\n"
"        price.value = priceInUsd;\n"
"        price.persist();\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:246
msgid "The complete example is available in the `kafka-panache-quickstart` {quickstarts-tree-url}/kafka-panache-quickstart[directory]."
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:250
msgid "There are 2 `@Blocking` annotations:"
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:252
msgid "`io.smallrye.reactive.messaging.annotations.Blocking`"
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:253
msgid "`io.smallrye.common.annotation.Blocking`"
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:258
msgid "They have the same effect.  Thus, you can use both.  The first one provides more fine-grain tuning such as the worker pool to use and whether it preserves the order.  The second one, used also with other reactive features of Quarkus, uses the default worker pool and preserves the order."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:260
#, no-wrap
msgid "Acknowledgment Strategies"
msgstr ""

#.  No, it will be ack then the produced message get acked -> Needs confirmation
#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:269
msgid "All messages received by a consumer must be acknowledged.  In the absence of acknowledgment, the processing is considered on error.  If the consumer method receives a `Record` or a payload, the message will be acked on method return, also known as `Strategy.POST_PROCESSING`.  If the consumer method returns another reactive stream or `CompletableStage`, the message will be acked when the downstream message is acked.  You can override the default behavior to ack the message on arrival (`Strategy.PRE_PROCESSING`), or do not ack the message at all (`Strategy.NONE`) on the consumer method as in the following example:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:277
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"@Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING)\n"
"public void process(double price) {\n"
"    // process price\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:281
msgid "If the consumer method receives a `Message`, the acknowledgment strategy is `Strategy.MANUAL` and the consumer method is in charge of ack/nack the message."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:289
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public CompletableStage<Void> process(Message<Double> msg) {\n"
"    // process price\n"
"    return msg.ack();\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:292
msgid "As mentioned above, the method can also override the acknowledgment strategy to `PRE_PROCESSING` or `NONE`."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:294
#, no-wrap
msgid "Commit Strategies"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:300
msgid "When a message produced from a Kafka record is acknowledged, the connector invokes a commit strategy.  These strategies decide when the consumer offset for a specific topic/partition is committed.  Committing an offset indicates that all previous records have been processed.  It is also the position where the application would restart the processing after a crash recovery or a restart."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:303
msgid "Committing every offset has performance penalties as Kafka offset management can be slow.  However, not committing the offset often enough may lead to message duplication if the application crashes between two commits."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:305
msgid "The Kafka connector supports three strategies:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:314
msgid "`throttled` keeps track of received messages and commits to the next offset after the latest acked message in sequence.  This strategy guarantees at-least-once delivery even if the channel performs asynchronous processing.  The connector tracks the received records and periodically (period specified by `auto.commit.interval.ms` (default: 5000 ms)) commits the highest consecutive offset.  The connector will be marked as unhealthy if a message associated with a record is not acknowledged in `throttled.unprocessed-record-max-age.ms` (default: 60000 ms).  Indeed, this strategy cannot commit the offset as soon as a single record processing fails (see <<error-handling>> to configure what happens on failing processing).  If `throttled.unprocessed-record-max-age.ms` is set to less than or equal to `0`, it does not perform any health check verification.  Such a setting might lead to running out of memory if there are \"poison pill\" messages.  This strategy is the default if `enable.auto.commit` is not explicitly set to true."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:318
msgid "`latest` commits the record offset received by the Kafka consumer as soon as the associated message is acknowledged (if the offset is higher than the previously committed offset).  This strategy provides at-least-once delivery if the channel processes the message without performing any asynchronous processing.  This strategy should not be used on high-load as offset commit is expensive. However, it reduces the risk of duplicates."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:323
msgid "`ignore` performs no commit. This strategy is the default strategy when the consumer is explicitly configured with `enable.auto.commit` to true.  It delegates the offset commit to the underlying Kafka client.  This strategy provides at-least-once delivery if the channel processes the message without performing any asynchronous operations and when `enable.auto.commit` is set to true.  However, if the processing failed between two commits, messages received after the commit and before the failure will be re-processed."
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:328
msgid "The Kafka connector disables the Kafka auto commit when it is not explicitly enabled. This behavior differs from the traditional Kafka consumer.  If high-throughout is important for you, and not limited by the downstream, we recommend to either:"
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:330
msgid "Use the `throttled` policy"
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:331
msgid "or set `enable.auto.commit` to true and annotate the consuming method with `@Acknowledgment(Acknowledgment.Strategy.NONE)`"
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:334
#, no-wrap
msgid "Error Handling Strategies"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:337
msgid "If a message produced from a Kafka record is nacked, a failure strategy is applied. The Kafka connector supports three strategies:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:339
msgid "`fail`: fail the application, no more records will be processed (default strategy). The offset of the record that has not been processed correctly is not committed."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:340
msgid "`ignore`: the failure is logged, but the processing continue. The offset of the record that has not been processed correctly is committed."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:341
msgid "`dead-letter-queue`: the offset of the record that has not been processed correctly is committed, but the record is written to a (Kafka) dead letter queue topic."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:343
msgid "The strategy is selected using the `failure-strategy` attribute."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:345
msgid "In the case of `dead-letter-queue`, you can configure the following attributes:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:347
msgid "`dead-letter-queue.topic`: the topic to use to write the records not processed correctly, default is `dead-letter-topic-$channel`, with `$channel` being the name of the channel."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:348
msgid "`dead-letter-queue.key.serializer`: the serializer used to write the record key on the dead letter queue. By default, it deduces the serializer from the key deserializer."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:349
msgid "`dead-letter-queue.value.serializer`: the serializer used to write the record value on the dead letter queue. By default, it deduces the serializer from the value deserializer."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:351
msgid "The record written on the dead letter queue contains a set of additional headers about the original record:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:353
#, no-wrap
msgid "*dead-letter-reason*: the reason of the failure\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:354
#, no-wrap
msgid "*dead-letter-cause*: the cause of the failure if any\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:355
#, no-wrap
msgid "*dead-letter-topic*: the original topic of the record\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:356
#, no-wrap
msgid "*dead-letter-partition*: the original partition of the record (integer mapped to String)\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:357
#, no-wrap
msgid "*dead-letter-offset*: the original offset of the record (long mapped to String)\n"
msgstr ""

#. type: Title ====
#: upstream/_versions/main/guides/kafka.adoc:358
#, no-wrap
msgid "Retrying processing"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:361
msgid "You can combine Reactive Messaging with https://github.com/smallrye/smallrye-fault-tolerance[SmallRye Fault Tolerance], and retry processing if it failed:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:369
#, no-wrap
msgid ""
"@Incoming(\"kafka\")\n"
"@Retry(delay = 10, maxRetries = 5)\n"
"public void consume(String v) {\n"
"   // ... retry if this method throws an exception\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:372
msgid "You can configure the delay, the number of retries, the jitter..."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:374
msgid "If your method returns a `Uni`, you need to add the `@NonBlocking` annotation:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:384
#, no-wrap
msgid ""
"@Incoming(\"kafka\")\n"
"@Incoming(\"processed\")\n"
"@Retry(delay = 10, maxRetries = 5)\n"
"@NonBlocking\n"
"public Uni<String> consume(String v) {\n"
"   // ... retry if this method throws an exception or the returned Uni produce a failure\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:389
msgid "The incoming messages are acknowledged only once the processing completes successfully.  So, it commits the offset after the successful processing.  If after the retries the processing still failed, the message is _nacked_ and the failure strategy is applied."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:390
#, no-wrap
msgid "Consumer Groups"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:397
msgid "In Kafka, a consumer group is a set of consumers which cooperate to consume data from a topic.  A topic is divided into a set of partitions.  The partitions of a topic are assigned among the consumers in the group, effectively allowing to scale consumption throughput.  Note that each partition is assigned to a single consumer from a group.  However, a consumer can be assigned to multiple partitions if the number of partitions is greater than the number of consumer in the group."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:399
msgid "Let's explore briefly different producer/consumer patterns and how to implement them using Quarkus:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:401
#, no-wrap
msgid "*Single consumer thread inside a consumer group*\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:405
msgid "This is the default behavior of an application subscribing to a Kafka topic: Each Kafka connector will create a single consumer thread and place it inside a single consumer group.  Consumer group id defaults to the application name as set by the `quarkus.application.name` configuration property.  It can also be set using the `kafka.group.id` property."
msgstr ""

#. type: Named 'alt' AttributeList argument for macro 'image'
#: upstream/_versions/main/guides/kafka.adoc:406
#: upstream/_versions/main/guides/kafka.adoc:414
#: upstream/_versions/main/guides/kafka.adoc:421
#: upstream/_versions/main/guides/kafka.adoc:429
#, no-wrap
msgid "Architecture,"
msgstr ""

#. type: Target for macro image
#: upstream/_versions/main/guides/kafka.adoc:406
#, no-wrap
msgid "kafka-one-app-one-consumer.png"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:409
#, no-wrap
msgid "*Multiple consumer threads inside a consumer group*\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:413
msgid "For a given application instance, the number of consumers inside the consumer group can be configured using `mp.messaging.incoming.$channel.partitions` property.  The partitions of the subscribed topic will be divided among the consumer threads.  Note that if the `partitions` value exceed the number of partitions of the topic, some consumer threads won't be assigned any partitions."
msgstr ""

#. type: Target for macro image
#: upstream/_versions/main/guides/kafka.adoc:414
#, no-wrap
msgid "kafka-one-app-two-consumers.png"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:417
#, no-wrap
msgid "*Multiple consumer applications inside a consumer group*\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:420
msgid "Similar to the previous example, multiple instances of an application can subscribe to a single consumer group, configured via `mp.messaging.incoming.$channel.group.id` property, or left default to the application name.  This in turn will divide partitions of the topic among application instances."
msgstr ""

#. type: Target for macro image
#: upstream/_versions/main/guides/kafka.adoc:421
#, no-wrap
msgid "kafka-two-app-one-consumer-group.png"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:424
#, no-wrap
msgid "*Pub/Sub: Multiple consumer groups subscribed to a topic*\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:428
msgid "Lastly different applications can subscribe independently to same topics setting different *consumer group ids*.  For example, messages published to a topic called _orders_ can be consumed independently on two consumer applications, one with `mp.messaging.incoming.orders.group.id=invoicing` and second with `mp.messaging.incoming.orders.group.id=shipping`.  Different consumer groups can scale thus independently according to the message consumption requirements."
msgstr ""

#. type: Target for macro image
#: upstream/_versions/main/guides/kafka.adoc:429
#, no-wrap
msgid "kafka-two-app-two-consumer-groups.png"
msgstr ""

#. type: Title ====
#: upstream/_versions/main/guides/kafka.adoc:431
#, no-wrap
msgid "Consumer Rebalance Listener"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:438
msgid "Inside a consumer group, as new group members arrive and old members leave, the partitions are re-assigned so that each member receives a proportional share of the partitions.  This is known as rebalancing the group.  To handle offset commit and assigned partitions yourself, you can provide a consumer rebalance listener.  To achieve this, implement the `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` interface and exposed it as a `@Idenfier` bean.  A common use case is to store offset in a separate data store to implement exactly-once semantic, or starting the processing at a specific offset."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:442
msgid "The listener is invoked every time the consumer topic/partition assignment changes.  For example, when the application starts, it invokes the `partitionsAssigned` callback with the initial set of topics/partitions associated with the consumer.  If, later, this set changes, it calls the `partitionsRevoked` and `partitionsAssigned` callbacks again, so you can implement custom logic."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:445
msgid "Note that the rebalance listener methods are called from the Kafka polling thread and **will** block the caller thread until completion.  That’s because the rebalance protocol has synchronization barriers, and using asynchronous code in a rebalance listener may be executed after the synchronization barrier."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:447
msgid "When topics/partitions are assigned or revoked from a consumer, it pauses the message delivery and resumes once the rebalance completes."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:451
msgid "If the rebalance listener handles offset commit on behalf of the user (using the `NONE` commit strategy), the rebalance listener must commit the offset synchronously in the partitionsRevoked callback.  We also recommend applying the same logic when the application stops."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:453
msgid "Unlike the `ConsumerRebalanceListener` from Apache Kafka, the `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` methods pass the Kafka Consumer and the set of topics/partitions."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:457
msgid "In the following example we set-up a consumer that always starts on messages from at most 10 minutes ago (or offset 0).  First we need to provide a bean managed implementation of `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` annotated with `io.smallrye.common.annotation.Identifier`.  We then must configure our inbound connector to use this bean."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:461
#: upstream/_versions/main/guides/kafka.adoc:511
#, no-wrap
msgid "package inbound;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:467
#, no-wrap
msgid ""
"import io.smallrye.common.annotation.Identifier;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener;\n"
"import org.apache.kafka.clients.consumer.Consumer;\n"
"import org.apache.kafka.clients.consumer.OffsetAndTimestamp;\n"
"import org.apache.kafka.clients.consumer.TopicPartition;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:473
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import java.util.Collection;\n"
"import java.util.HashMap;\n"
"import java.util.Map;\n"
"import java.util.logging.Logger;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:477
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"@Identifier(\"rebalanced-example.rebalancer\")\n"
"public class KafkaRebalancedConsumerRebalanceListener implements KafkaConsumerRebalanceListener {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:479
#, no-wrap
msgid "    private static final Logger LOGGER = Logger.getLogger(KafkaRebalancedConsumerRebalanceListener.class.getName());\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:491
#, no-wrap
msgid ""
"    /**\n"
"     * When receiving a list of partitions will search for the earliest offset within 10 minutes\n"
"     * and seek the consumer to it.\n"
"     *\n"
"     * @param consumer   underlying consumer\n"
"     * @param partitions set of assigned topic partitions\n"
"     */\n"
"    @Override\n"
"    public void onPartitionsAssigned(Consumer<?, ?> consumer, Collection<TopicPartition> partitions) {\n"
"        long now = System.currentTimeMillis();\n"
"        long shouldStartAt = now - 600_000L; //10 minute ago\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:504
#, no-wrap
msgid ""
"        Map<TopicPartition, Long> request = new HashMap<>();\n"
"        for (TopicPartition partition : partitions) {\n"
"            LOGGER.info(\"Assigned \" + partition);\n"
"            request.put(partition, shouldStartAt);\n"
"        }\n"
"        Map<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(request);\n"
"        for (Map.Entry<TopicPartition, OffsetAndTimestamp> position : offsets.entrySet()) {\n"
"            long target = position.getValue() == null ? 0L : position.getValue().offset();\n"
"            LOGGER.info(\"Seeking position \" + target + \" for \" + position.getKey());\n"
"            consumer.seek(position.getKey(), target);\n"
"        }\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:515
#, no-wrap
msgid ""
"import io.smallrye.reactive.messaging.kafka.IncomingKafkaRecord;\n"
"import org.eclipse.microprofile.reactive.messaging.Acknowledgment;\n"
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:519
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import java.util.concurrent.CompletableFuture;\n"
"import java.util.concurrent.CompletionStage;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:522
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class KafkaRebalancedConsumer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:529
#, no-wrap
msgid ""
"    @Incoming(\"rebalanced-example\")\n"
"    @Acknowledgment(Acknowledgment.Strategy.NONE)\n"
"    public CompletionStage<Void> consume(IncomingKafkaRecord<Integer, String> message) {\n"
"        // We don't need to ACK messages because in this example we set offset during consumer re-balance\n"
"        return CompletableFuture.completedFuture(null);\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:535
msgid "To configure the inbound connector to use the provided listener we either set the consumer rebalance listener’s identifier: `mp.messaging.incoming.rebalanced-example.consumer-rebalance-listener.name=rebalanced-example.rebalancer`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:537
msgid "Or have the listener’s name be the same as the group id:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:539
msgid "`mp.messaging.incoming.rebalanced-example.group.id=rebalanced-example.rebalancer`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:541
msgid "Setting the consumer re-balance listener’s name takes precedence over using the group id."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:543
#, no-wrap
msgid "Sending messages to Kafka"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:546
msgid "Configuration for the Kafka connector outgoing channels is similar to that of incoming:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:552
#, no-wrap
msgid ""
"%prod.kafka.bootstrap.servers=kafka:9092 <1>\n"
"mp.messaging.outgoing.prices-out.connector=smallrye-kafka <2>\n"
"mp.messaging.outgoing.prices-out.topic=prices <3>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:557
msgid "Configure the broker location for the production profile. You can configure it globally or per channel using `mp.messaging.outgoing.$channel.bootstrap.servers` property.  In dev mode and when running tests, link:kafka-dev-services.adoc[Dev Services for Kafka] automatically starts a Kafka broker.  When not provided this property defaults to `localhost:9092`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:558
msgid "Configure the connector to manage the prices channel."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:559
msgid "By default the topic name is same as the channel name. You can configure the topic attribute to override it."
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:563
msgid "Inside an application configuration channel names are unique. Therefore if you'd like to configure an incoming and outgoing channel on the same topic, you will need to name channels differently (like in the examples of this guide, `mp.messaging.incoming.prices` and `mp.messaging.outgoing.prices-out`)."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:567
msgid "Then, your application can generate messages and publish them to the prices channel.  It can use double payloads as in the following snippet:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:572
#, no-wrap
msgid ""
"import io.smallrye.mutiny.Multi;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:576
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import java.time.Duration;\n"
"import java.util.Random;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:579
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class KafkaPriceProducer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:581
#: upstream/_versions/main/guides/kafka.adoc:844
#, no-wrap
msgid "    private final Random random = new Random();\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:589
#, no-wrap
msgid ""
"    @Outgoing(\"prices-out\")\n"
"    public Multi<Double> generate() {\n"
"        // Build an infinite stream of random prices\n"
"        // It emits a price every second\n"
"        return Multi.createFrom().ticks().every(Duration.ofSeconds(1))\n"
"            .map(x -> random.nextDouble());\n"
"    }\n"
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:596
msgid "You should not call methods annotated with `@Incoming` and/or `@Outgoing` directly from your code. They are invoked by the framework. Having user code invoking them would not have the expected outcome."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:600
msgid "Note that the `generate` method returns a `Multi<Double>`, which implements the Reactive Streams `Publisher` interface.  This publisher will be used by the framework to generate messages and send it to the configured Kafka topic."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:602
msgid "Instead of returning a payload, you can return a `io.smallrye.reactive.messaging.kafka.Record` to send key/value pairs:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:610
#, no-wrap
msgid ""
"@Outgoing(\"out\")\n"
"public Multi<Record<String, Double>> generate() {\n"
"    return Multi.createFrom().ticks().every(Duration.ofSeconds(1))\n"
"        .map(x -> Record.of(\"my-key\", random.nextDouble()));\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:613
msgid "Payload can be wrapped inside `org.eclipse.microprofile.reactive.messaging.Message` to have more control on the written records:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:626
#, no-wrap
msgid ""
"@Outgoing(\"generated-price\")\n"
"public Multi<Message<Double>> generate() {\n"
"    return Multi.createFrom().ticks().every(Duration.ofSeconds(1))\n"
"            .map(x -> Message.of(random.nextDouble())\n"
"                    .addMetadata(OutgoingKafkaRecordMetadata.<String>builder()\n"
"                            .withKey(\"my-key\")\n"
"                            .withTopic(\"my-key-prices\")\n"
"                            .withHeaders(new RecordHeaders().add(\"my-header\", \"value\".getBytes()))\n"
"                            .build()));\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:631
msgid "`OutgoingKafkaRecordMetadata` allows to set metadata attributes of the Kafka record, such as `key`, `topic`, `partition` or `timestamp`.  One use case is to set dynamically select the destination topic of a message.  In this case, instead of configuring the topic inside your application configuration file, you need to use the outbound metadata to set the name of the topic."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:634
msgid "Other than method signatures returning a Reactive Stream `Publisher` (`Multi` being an implementation of `Publisher`), outgoing method can also return single message.  In this case the producer will use this method as generator to create an infinite stream."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:638
#, no-wrap
msgid "@Outgoing(\"prices-out\") T generate(); // T excluding Void\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:640
#, no-wrap
msgid "@Outgoing(\"prices-out\") Message<T> generate();\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:642
#, no-wrap
msgid "@Outgoing(\"prices-out\") CompletionStage<T> generate();\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:644
#, no-wrap
msgid "@Outgoing(\"prices-out\") CompletionStage<Message<T>> generate();\n"
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:646
#, no-wrap
msgid "Sending messages with @Emitter"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:649
msgid "Sometimes, you need to have an imperative way of sending messages."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:652
msgid "For example, if you need to send a message to a stream when receiving a POST request inside a REST endpoint.  In this case, you cannot use `@Outgoing` because your method has parameters."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:654
msgid "For this, you can use an `Emitter`."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:659
#, no-wrap
msgid ""
"import org.eclipse.microprofile.reactive.messaging.Channel;\n"
"import org.eclipse.microprofile.reactive.messaging.Emitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:665
#: upstream/_versions/main/guides/kafka.adoc:708
#: upstream/_versions/main/guides/kafka.adoc:742
#, no-wrap
msgid ""
"import javax.inject.Inject;\n"
"import javax.ws.rs.POST;\n"
"import javax.ws.rs.Path;\n"
"import javax.ws.rs.Consumes;\n"
"import javax.ws.rs.core.MediaType;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:670
#: upstream/_versions/main/guides/kafka.adoc:713
#, no-wrap
msgid "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:677
#, no-wrap
msgid ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public void addPrice(Double price) {\n"
"        CompletionStage<Void> ack = priceEmitter.send(price);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:680
msgid "Sending a payload returns a `CompletionStage`, completed when the message is acked. If the message transmission fails, the `CompletionStage` is completed exceptionally with the reason of the nack."
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:684
msgid "The `Emitter` configuration is done the same way as the other stream configuration used by `@Incoming` and `@Outgoing`."
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:693
msgid "Using the `Emitter` you are sending messages from your imperative code to reactive messaging.  These messages are stored in a queue until they are sent.  If the Kafka producer client can't keep up with messages trying to be sent over to Kafka, this queue can become a memory hog and you may even run out of memory.  You can use `@OnOverflow` to configure back-pressure strategy.  It lets you configure the size of the queue (default is 256) and the strategy to apply when the buffer size is reached. Available strategies are `DROP`, `LATEST`, `FAIL`, `BUFFER`, UNBOUNDED_BUFFER` and `NONE`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:696
msgid "With the `Emitter` API you can also encapsulate the outgoing payload inside `Message<T>`. As with the previous examples, `Message` lets you handle the ack/nack cases differently."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:702
#, no-wrap
msgid ""
"import java.util.concurrent.CompletableFuture;\n"
"import org.eclipse.microprofile.reactive.messaging.Channel;\n"
"import org.eclipse.microprofile.reactive.messaging.Emitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:728
#, no-wrap
msgid ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public void addPrice(Double price) {\n"
"        priceEmitter.send(Message.of(price)\n"
"            .withAck(() -> {\n"
"                // Called when the message is acked\n"
"                return CompletableFuture.completedFuture(null);\n"
"            })\n"
"            .withNack(throwable -> {\n"
"                // Called when the message is nacked\n"
"                return CompletableFuture.completedFuture(null);\n"
"            }));\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:732
msgid "If you prefer using Reactive Stream APIs you can use `MutinyEmitter` that will return `Uni<Void>` on the send method.  You can therefore use Mutiny APIs for handling downstream messages and errors."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:736
#, no-wrap
msgid "import org.eclipse.microprofile.reactive.messaging.Channel;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:744
#, no-wrap
msgid "import io.smallrye.reactive.messaging.MutinyEmitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:749
#, no-wrap
msgid "    @Inject @Channel(\"price-create\") MutinyEmitter<Double> priceEmitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:758
#, no-wrap
msgid ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public Uni<String> addPrice(Double price) {\n"
"        return quoteRequestEmitter.send(price)\n"
"                .map(x -> \"ok\")\n"
"                .onFailure().recoverWithItem(\"ko\");\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:762
msgid "There’s also the ability to block on sending the event to the emitter with `sendAndAwait` method.  It will only return from the method when the event is acked or nacked by the receiver."
msgstr ""

#. type: Block title
#: upstream/_versions/main/guides/kafka.adoc:764
#, no-wrap
msgid "Deprecation"
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:767
msgid "The `io.smallrye.reactive.messaging.annotations.Emitter`, `io.smallrye.reactive.messaging.annotations.Channel` and `io.smallrye.reactive.messaging.annotations.OnOverflow` classes are now deprecated and replaced by:"
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:769
msgid "`org.eclipse.microprofile.reactive.messaging.Emitter`"
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:770
msgid "`org.eclipse.microprofile.reactive.messaging.Channel`"
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:771
msgid "`org.eclipse.microprofile.reactive.messaging.OnOverflow`"
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:773
msgid "The new `Emitter.send` method returns a `CompletionStage` completed when the produced message is acknowledged."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:775
#, no-wrap
msgid "Write Acknowledgement"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:779
msgid "When Kafka broker receives a record, its acknowledgement can take time depending on the configuration.  Also, it stores in-memory the records that cannot be written."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:782
msgid "By default, the connector does wait for Kafka to acknowledge the record to continue the processing (acknowledging the received Message).  You can disable this by setting the `waitForWriteCompletion` attribute to `false`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:784
msgid "Note that the `acks` attribute has a huge impact on the record acknowledgement."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:786
msgid "If a record cannot be written, the message is nacked."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:787
#, no-wrap
msgid "Backpressure"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:791
msgid "The Kafka outbound connector handles back-pressure, monitoring the number of in-flight messages waiting to be written to the Kafka broker.  The number of in-flight messages is configured using the `max-inflight-messages` attribute and defaults to 1024."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:796
msgid "The connector only sends that amount of messages concurrently.  No other messages will be sent until at least one in-flight message gets acknowledged by the broker.  Then, the connector writes a new message to Kafka when one of the broker’s in-flight messages get acknowledged.  Be sure to configure Kafka’s `batch.size` and `linger.ms` accordingly."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:799
msgid "You can also remove the limit of in-flight messages by setting `max-inflight-messages` to `0`.  However, note that the Kafka Producer may block if the number of requests reaches `max.in.flight.requests.per.connection`."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:800
#, no-wrap
msgid "Retrying message dispatch"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:805
msgid "When the Kafka producer receives an error from the server, if it is a transient, recoverable error, the client will retry sending the batch of messages.  This behavior is controlled by `retries` and `retry.backoff.ms` parameters.  In addition to this, Smallrye reactive messaging will retry individual messages on recoverable errors, depending on the `retries` and `delivery.timeout.ms` parameters."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:808
msgid "Note that while having retries in a reliable system is a best practice, the `max.in.flights.requests.per.session` parameter defaults to `5`, meaning that the order of the messages is not guaranteed.  If the message order is a must for your use case, setting `max.in.flights.requests.per.session` to `1` will make sure a single batch of messages is sent at a time, in the expense of limiting the throughput of the producer."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:810
msgid "For applying retry mechanism on processing errors see the section on <<retrying-processing>>."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:811
#, no-wrap
msgid "In-memory channels"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:815
msgid "In some use cases it is convenient to use the messaging patterns to transfer messages inside the same application.  When you don't connect a channel to a messaging backend like Kafka, everything happens in-memory, and the streams are created by chaining methods altogether.  Each chain is still a reactive stream and enforces the back-pressure protocol."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:819
msgid "The framework verifies that the producer/consumer chain is complete, meaning that if the application writes messages into an in-memory channel (using a method with only `@Outgoing`, or an `Emitter`), it must also consume the messages from within the application (using a method with only `@Incoming` or using an unmanaged stream)."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:821
#, no-wrap
msgid "Broadcasting messages on multiple consumers"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:826
msgid "By default, a channel can be linked to a single consumer, using `@Incoming` method or `@Channel` reactive stream.  At application startup, channels are verified to form a chain of consumers and producers with single consumer and producer.  You can override this behavior by setting `mp.messaging.$channel.broadcast=true` on a channel."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:828
msgid "In case of in-memory channels, `@Broadcast` annotation can be used on the `@Outgoing` method. For example,"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:832
#, no-wrap
msgid "import java.util.Random;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:837
#: upstream/_versions/main/guides/kafka.adoc:879
#: upstream/_versions/main/guides/kafka.adoc:907
#, no-wrap
msgid ""
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:839
#, no-wrap
msgid "import io.smallrye.reactive.messaging.annotations.Broadcast;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:842
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class MultipleConsumer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:850
#, no-wrap
msgid ""
"    @Outgoing(\"in-memory-channel\")\n"
"    @Broadcast\n"
"    double generate() {\n"
"        return random.nextDouble();\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:855
#, no-wrap
msgid ""
"    @Incoming(\"in-memory-channel\")\n"
"    void consumeAndLog(double price) {\n"
"        System.out.println(price);\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:862
#, no-wrap
msgid ""
"    @Incoming(\"in-memory-channel\")\n"
"    @Outgoing(\"prices2\")\n"
"    double consumeAndSend(double price) {\n"
"        return price;\n"
"    }\n"
"}\n"
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:868
msgid "Reciprocally multiple producers on the same channel can be merged by setting `mp.messaging.incoming.$channel.merge=true`.  On the `@Incoming` methods you can control how multiple channels are merged using `@Merge` annotation."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:870
#, no-wrap
msgid "Processing Messages"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:874
msgid "Often applications streaming data need to consume some events from a topic, process them and publish the result to a different topic.  A processor method can be simply implemented using both the `@Incoming` and `@Outgoing` annotations:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:884
#: upstream/_versions/main/guides/kafka.adoc:912
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class PriceProcessor {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:886
#: upstream/_versions/main/guides/kafka.adoc:914
#: upstream/_versions/main/guides/kafka.adoc:1043
#, no-wrap
msgid "    private static final double CONVERSION_RATE = 0.88;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:892
#, no-wrap
msgid ""
"    @Incoming(\"price-in\")\n"
"    @Outgoing(\"price-out\")\n"
"    public double process(double price) {\n"
"        return price * CONVERSION_RATE;\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:898
msgid "The parameter of the `process` method is the incoming message payload, whereas the return will be used as the outgoing messaage payload.  Previously mentioned signatures for parameter and return types, as described in previous sections are supported, such as `Message<T>`, `Record<K, V>` etc."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:900
msgid "You can apply asynchronous stream processing by consuming and returning reactive stream `Multi<T>` type:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:909
#, no-wrap
msgid "import io.smallrye.mutiny.Multi;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:920
#, no-wrap
msgid ""
"    @Incoming(\"price-in\")\n"
"    @Outgoing(\"price-out\")\n"
"    public Multi<Double> process(Multi<Integer> prices) {\n"
"        return prices.filter(p -> p > 100).map(p -> p * CONVERSION_RATE);\n"
"    }\n"
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:925
#, no-wrap
msgid "Accessing Kafka clients directly"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:929
msgid "In rare cases you may need to access the underlying Kafka clients.  `KafkaClientService` provides thread-safe access to `Producer` and `Consumer`."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:935
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.enterprise.event.Observes;\n"
"import javax.inject.Inject;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:937
#, no-wrap
msgid "import org.apache.kafka.clients.producer.ProducerRecord;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:942
#, no-wrap
msgid ""
"import io.quarkus.runtime.StartupEvent;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaClientService;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaConsumer;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaProducer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:945
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class PriceSender {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:948
#, no-wrap
msgid ""
"    @Inject\n"
"    KafkaClientService clientService;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:955
#, no-wrap
msgid ""
"    void onStartup(@Observes StartupEvent startupEvent) {\n"
"        KafkaProducer<String, Double> producer = clientService.getProducer(\"generated-price\");\n"
"        producer.runOnSendingThread(client -> client.send(new ProducerRecord<>(\"prices\", 2.4)))\n"
"            .await().indefinitely();\n"
"    }\n"
"}\n"
msgstr ""

#. type: delimited block =
#: upstream/_versions/main/guides/kafka.adoc:960
msgid "The `KafkaClientService` is an experimental API and can change in the future."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:963
msgid "You can also get the Kafka configuration injected to your application and create Kafka producer, consumer and admin clients directly:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:970
#, no-wrap
msgid ""
"import io.smallrye.common.annotation.Identifier;\n"
"import org.apache.kafka.clients.admin.AdminClient;\n"
"import org.apache.kafka.clients.admin.AdminClientConfig;\n"
"import org.apache.kafka.clients.admin.KafkaAdminClient;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:976
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.enterprise.inject.Produces;\n"
"import javax.inject.Inject;\n"
"import java.util.HashMap;\n"
"import java.util.Map;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:979
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class KafkaClients {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:983
#, no-wrap
msgid ""
"    @Inject\n"
"    @Identifier(\"default-kafka-broker\")\n"
"    Map<String, Object> config;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:994
#, no-wrap
msgid ""
"    @Produces\n"
"    AdminClient getAdmin() {\n"
"        Map<String, Object> copy = new HashMap<>();\n"
"        for (Map.Entry<String, Object> entry : config.entrySet()) {\n"
"            if (AdminClientConfig.configNames().contains(entry.getKey())) {\n"
"                copy.put(entry.getKey(), entry.getValue());\n"
"            }\n"
"        }\n"
"        return KafkaAdminClient.create(copy);\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1000
msgid "This configuration map will contain all Kafka related properties configured inside `application.properties` file."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1002
#, no-wrap
msgid "JSON serialization"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1005
msgid "Quarkus has built-in capabilities to deal with JSON Kafka messages."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1007
msgid "Imagine we have a `Fruit` pojo as follows:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1011
#, no-wrap
msgid "public class Fruit {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1014
#, no-wrap
msgid ""
"    public String name;\n"
"    public int price;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1017
#, no-wrap
msgid ""
"    public Fruit() {\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1023
#, no-wrap
msgid ""
"    public Fruit(String name, int price) {\n"
"        this.name = name;\n"
"        this.price = price;\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1026
msgid "And we want to use it to receive messages from Kafka, make some price transformation, and send messages back to Kafka."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1032
#, no-wrap
msgid ""
"import io.smallrye.reactive.messaging.annotations.Broadcast;\n"
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1041
#, no-wrap
msgid ""
"/**\n"
"* A bean consuming data from the \"fruit-in\" Kafka topic and applying some price conversion.\n"
"* The result is pushed to the \"fruit-out\" stream.\n"
"*/\n"
"@ApplicationScoped\n"
"public class FruitProcessor {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1051
#, no-wrap
msgid ""
"    @Incoming(\"fruit-in\")\n"
"    @Outgoing(\"fruit-out\")\n"
"    @Broadcast\n"
"    public Fruit process(Fruit fruit) {\n"
"        fruit.price = fruit.price * CONVERSION_RATE;\n"
"        return fruit;\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1056
msgid "To do this, we will need to setup JSON serialization with Jackson or JSON-B."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1058
msgid "With JSON serialization correctly configured, you can also use `Publisher<Fruit>` and `Emitter<Fruit>`."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1060
#, no-wrap
msgid "Serializing via Jackson"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1063
msgid "First, you need to include the `quarkus-jackson` extension."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1070
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-jackson</artifactId>\n"
"</dependency>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1074
msgid "There is an existing `ObjectMapperSerializer` that can be used to serialize all pojos via Jackson.  You may create an empty subclass if you want to use <<serialization-autodetection>>."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1077
msgid "The corresponding deserializer class needs to be subclassed.  So, let's create a `FruitDeserializer` that extends the `ObjectMapperDeserializer`."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1081
#, no-wrap
msgid "package com.acme.fruit.jackson;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1083
#, no-wrap
msgid "import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1090
#, no-wrap
msgid ""
"public class FruitDeserializer extends ObjectMapperDeserializer<Fruit> {\n"
"    public FruitDeserializer() {\n"
"        // pass the class to the parent.\n"
"        super(Fruit.class);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1093
msgid "Finally, configure your streams to use the Jackson serializer and deserializer."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1100
#, no-wrap
msgid ""
"# Configure the Kafka source (we read from it)\n"
"mp.messaging.incoming.fruit-in.connector=smallrye-kafka\n"
"mp.messaging.incoming.fruit-in.topic=fruit-in\n"
"mp.messaging.incoming.fruit-in.value.deserializer=com.acme.fruit.jackson.FruitDeserializer\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1105
#, no-wrap
msgid ""
"# Configure the Kafka sink (we write to it)\n"
"mp.messaging.outgoing.fruit-out.connector=smallrye-kafka\n"
"mp.messaging.outgoing.fruit-out.topic=fruit-out\n"
"mp.messaging.outgoing.fruit-out.value.serializer=io.quarkus.kafka.client.serialization.ObjectMapperSerializer\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1109
msgid "Now, your Kafka messages will contain a Jackson serialized representation of your Fruit pojo.  In this case `serializer` and `deserializer` configurations are not necessary as the <<serialization-autodetection>> is enabled by default."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1111
#, no-wrap
msgid "Serializing via JSON-B"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1114
msgid "First, you need to include the `quarkus-jsonb` extension."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1121
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-jsonb</artifactId>\n"
"</dependency>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1125
msgid "There is an existing `JsonbSerializer` that can be used to serialize all pojos via JSON-B.  You may create an empty subclass if you want to use <<serialization-autodetection>>."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1128
msgid "The corresponding deserializer class needs to be subclassed.  So, let's create a `FruitDeserializer` that extends the generic `JsonbDeserializer`."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1132
#, no-wrap
msgid "package com.acme.fruit.jsonb;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1134
#, no-wrap
msgid "import io.quarkus.kafka.client.serialization.JsonbDeserializer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1141
#, no-wrap
msgid ""
"public class FruitDeserializer extends JsonbDeserializer<Fruit> {\n"
"    public FruitDeserializer() {\n"
"        // pass the class to the parent.\n"
"        super(Fruit.class);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1144
msgid "Finally, configure your streams to use the JSON-B serializer and deserializer."
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1151
#, no-wrap
msgid ""
"# Configure the Kafka source (we read from it)\n"
"mp.messaging.incoming.fruit-in.connector=smallrye-kafka\n"
"mp.messaging.incoming.fruit-in.topic=fruit-in\n"
"mp.messaging.incoming.fruit-in.value.deserializer=com.acme.fruit.jsonb.FruitDeserializer\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1156
#, no-wrap
msgid ""
"# Configure the Kafka sink (we write to it)\n"
"mp.messaging.outgoing.fruit-out.connector=smallrye-kafka\n"
"mp.messaging.outgoing.fruit-out.topic=fruit-out\n"
"mp.messaging.outgoing.fruit-out.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1159
msgid "Now, your Kafka messages will contain a JSON-B serialized representation of your Fruit pojo."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1162
msgid "If you don't want to create a deserializer for each of your pojo, you can use the generic `io.vertx.kafka.client.serialization.JsonObjectDeserializer` that will deserialize to a `io.vertx.core.json.JsonObject`. The corresponding serializer can also be used: `io.vertx.kafka.client.serialization.JsonObjectSerializer`."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1163
#, no-wrap
msgid "Avro Serialization"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1166
#: upstream/_versions/main/guides/kafka.adoc:1237
msgid "This is described in a dedicated guide: link:kafka-schema-registry-avro.adoc[Using Apache Kafka with Schema Registry and Avro]."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1168
#, no-wrap
msgid "Serializer/deserializer autodetection"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1172
msgid "When using SmallRye Reactive Messaging with Kafka, Quarkus can often automatically detect the correct serializer and deserializer class.  This autodetection is based on declarations of `@Incoming` and `@Outgoing` methods, as well as injected ``@Channel``s."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1174
msgid "For example, if you declare"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1181
#, no-wrap
msgid ""
"@Outgoing(\"generated-price\")\n"
"public Multi<Integer> generate() {\n"
"    ...\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1184
msgid "and your configuration indicates that the `generated-price` channel uses the `smallrye-kafka` connector, then Quarkus will automatically set the `value.serializer` to Kafka's built-in `IntegerSerializer`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1186
msgid "Similarly, if you declare"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1193
#, no-wrap
msgid ""
"@Incoming(\"my-kafka-records\")\n"
"public void consume(KafkaRecord<Long, byte[]> record) {\n"
"    ...\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1196
msgid "and your configuration indicates that the `my-kafka-records` channel uses the `smallrye-kafka` connector, then Quarkus will automatically set the `key.deserializer` to Kafka's built-in `LongDeserializer`, as well as the `value.deserializer` to `ByteArrayDeserializer`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1198
msgid "Finally, if you declare"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1204
#, no-wrap
msgid ""
"@Inject\n"
"@Channel(\"price-create\")\n"
"Emitter<Double> priceEmitter;\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1207
msgid "and your configuration indicates that the `price-create` channel uses the `smallrye-kafka` connector, then Quarkus will automatically set the `value.serializer` to Kafka's built-in `DoubleSerializer`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1209
msgid "The full set of types supported by the serializer/deserializer autodetection is:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1211
msgid "`short` and `java.lang.Short`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1212
msgid "`int` and `java.lang.Integer`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1213
msgid "`long` and `java.lang.Long`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1214
msgid "`float` and `java.lang.Float`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1215
msgid "`double` and `java.lang.Double`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1216
msgid "`byte[]`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1217
msgid "`java.lang.String`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1218
msgid "`java.util.UUID`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1219
msgid "`java.nio.ByteBuffer`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1220
msgid "`org.apache.kafka.common.utils.Bytes`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1221
msgid "`io.vertx.core.buffer.Buffer`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1222
msgid "`io.vertx.core.json.JsonObject`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1223
msgid "`io.vertx.core.json.JsonArray`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1224
msgid "classes generated from Avro schemas, if Confluent or Apicurio _serde_ is present"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1225
msgid "see link:kafka-schema-registry-avro.adoc[Using Apache Kafka with Schema Registry and Avro] for more information about using Confluent or Apicurio libraries"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1226
msgid "classes for which a subclass of `ObjectMapperSerializer` / `ObjectMapperDeserializer` is present, as described in <<jackson-serialization>>"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1227
msgid "it is technically not needed to subclass `ObjectMapperSerializer`, but in such case, autodetection isn't possible"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1228
msgid "classes for which a subclass of `JsonbSerializer` / `JsonbDeserializer` is present, as described in <<jsonb-serialization>>"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1229
msgid "it is technically not needed to subclass `JsonbSerializer`, but in such case, autodetection isn't possible"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1233
msgid "In case you have any issues with serializer autodetection, you can switch it off completely by setting `quarkus.reactive-messaging.kafka.serializer-autodetection.enabled=false`.  If a serializer/deserializer is set by configuration it won't be replaced by the autodetection.  If you find you need to do this, please file a bug in the link:https://github.com/quarkusio/quarkus/issues[Quarkus issue tracker] so we can fix whatever problem you have."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1234
#, no-wrap
msgid "Using Schema Registry"
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1239
#, no-wrap
msgid "Health Checks"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1243
msgid "Quarkus provides several health checks for Kafka.  These checks are used in combination with the `quarkus-smallrye-health` extension."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1249
msgid "When using the `quarkus-kafka` extension, you can enable _readiness_ health check by setting the `quarkus.kafka.health.enabled` property to `true` in your `application.properties`.  This check reports the status of the interaction with a _default_ Kafka broker (configured using `kafka.bootstrap.servers`).  That check requires an _admin connection_ with the Kafka broker.  This check is disabled by default.  If enabled, when you access the `/q/health/ready` endpoint of your application, you will have information about the connection validation status."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1254
msgid "When using Reactive Messaging and the Kafka connector, each configured channel (incoming or outgoing) provides a _liveness_ and _readiness_ check.  The _liveness_ check captures any unrecoverable failure happening during the communication with Kafka.  The _readiness_ check verifies that communication with Kafka is established.  For each channel, you can disable the checks using:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1258
#, no-wrap
msgid "# Disable both liveness and readiness checks with `health-enabled=false`:\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1263
#, no-wrap
msgid ""
"# Incoming channel (receiving records form Kafka)\n"
"mp.messaging.incoming.your-channel.health-enabled=false\n"
"# Outgoing channel (writing records to Kafka)\n"
"mp.messaging.outgoing.your-channel.health-enabled=false\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1265
#, no-wrap
msgid "# Disable only the readiness check with `health-readiness-enabled=false`:\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1268
#, no-wrap
msgid ""
"mp.messaging.incoming.your-channel.health-readiness-enabled=false\n"
"mp.messaging.outgoing.your-channel.health-readiness-enabled=false\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1272
msgid "You can configure the `bootstrap.servers` for each channel using `mp.messaging.incoming|outgoing.$channel.bootstrap.servers` property.  Defaults is `kafka.bootstrap.servers`."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1276
msgid "Reactive Messaging readiness check offers two strategies.  The default strategy verifies that an active connection is established with the broker.  This approach is not intrusive as it's based on built-in metrics."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1279
msgid "Using the `health-readiness-topic-verification=true` attribute, you can also check the topics used by the application exist in the broker.  Note that, to achieve this, an _admin connection_ is required."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1280
#, no-wrap
msgid "Kafka Streams"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1283
msgid "This is described in a dedicated guide: link:kafka-streams.adoc[Using Apache Kafka Streams]."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1284
#, no-wrap
msgid "Using Snappy for message compression"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1287
msgid "On _outgoing_ channels, you can enable Snappy compression by setting the `compression.type` attribute to `snappy`:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1291
#, no-wrap
msgid "mp.messaging.outgoing.fruit-out.compression.type=snappy\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1295
msgid "In JVM mode, it will work out of the box.  However, to compile your application to a native executable, you need to:"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1297
msgid "Uses GraalVM 21.+"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1298
msgid "Add `quarkus.kafka.snappy.enabled=true` to your `application.properties`"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1300
msgid "In native mode, Snappy is disabled by default as the use of Snappy requires embedding a native library and unpacking it when the application starts."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1301
#, no-wrap
msgid "Authentication with OAuth"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1305
msgid "If your Kafka broker uses OAuth as authentication mechanism, you need to configure the Kafka consumer to enable this authentication process.  First, add the following dependency to your application:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1312
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.strimzi</groupId>\n"
"    <artifactId>kafka-oauth-client</artifactId>\n"
"</dependency>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1316
msgid "This dependency provides the callback handler required to handle the OAuth workflow.  Then, in the `application.properties`, add:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1326
#, no-wrap
msgid ""
"mp.messaging.connector.smallrye-kafka.security.protocol=SASL_PLAINTEXT\n"
"mp.messaging.connector.smallrye-kafka.sasl.mechanism=OAUTHBEARER\n"
"mp.messaging.connector.smallrye-kafka.sasl.jaas.config=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \\\n"
"  oauth.client.id=\"team-a-client\" \\\n"
"  oauth.client.secret=\"team-a-client-secret\" \\\n"
"  oauth.token.endpoint.uri=\"http://keycloak:8080/auth/realms/kafka-authz/protocol/openid-connect/token\" ;\n"
"mp.messaging.connector.smallrye-kafka.sasl.login.callback.handler.class=io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1329
msgid "Update the `oauth.client.id`, `oauth.client.secret` and `oauth.token.endpoint.uri` values."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1331
msgid "OAuth authentication works for both JVM and native modes."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1332
#, no-wrap
msgid "Testing a Kafka application"
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1334
#, no-wrap
msgid "Testing without a broker"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1338
msgid "It can be useful to test the application without having to start a Kafka broker.  To achieve this, you can _switch_ the channels managed by the Kafka connector to _in-memory_."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1340
msgid "This approach only works for JVM tests. It cannot be used for native tests (because they do not support injection)."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1342
msgid "First, add the following dependency to your application:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1350
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.smallrye.reactive</groupId>\n"
"    <artifactId>smallrye-reactive-messaging-in-memory</artifactId>\n"
"    <scope>test</scope>\n"
"</dependency>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1353
msgid "Then, create a Quarkus Test Resource as follows:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1357
#, no-wrap
msgid "public class KafkaTestResourceLifecycleManager implements QuarkusTestResourceLifecycleManager {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1367
#, no-wrap
msgid ""
"    @Override\n"
"    public Map<String, String> start() {\n"
"        Map<String, String> env = new HashMap<>();\n"
"        Map<String, String> props1 = InMemoryConnector.switchIncomingChannelsToInMemory(\"orders\");  // <1>\n"
"        Map<String, String> props2 = InMemoryConnector.switchOutgoingChannelsToInMemory(\"queue\");   // <2>\n"
"        env.putAll(props1);\n"
"        env.putAll(props2);\n"
"        return env;  // <3>\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1373
#, no-wrap
msgid ""
"    @Override\n"
"    public void stop() {\n"
"        InMemoryConnector.clear();  // <4>\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1375
msgid "Switch the incoming channel \"orders\" (expecting messages from Kafka) to in-memory."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1376
msgid "Switch the outgoing channel \"queue\" (writing messages to Kafka) to in-memory."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1377
msgid "Builds and returns a `Map` containing all the properties required to configure the application to use in-memory channels."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1378
msgid "When the test stops, clear the `InMemoryConnector` (discard all the received and sent messages)"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1380
msgid "Create a Quarkus Test using the test resource created above:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1386
#, no-wrap
msgid ""
"@QuarkusTest\n"
"@QuarkusTestResource(KafkaTestResourceLifecycleManager.class)\n"
"class BaristaTest {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1389
#, no-wrap
msgid ""
"    @Inject @Any\n"
"    InMemoryConnector connector; // <1>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1394
#, no-wrap
msgid ""
"    @Test\n"
"    void testProcessOrder() {\n"
"        InMemorySource<Order> orders = connector.source(\"orders\"); // <2>\n"
"        InMemorySink<Beverage> queue = connector.sink(\"queue\");    // <3>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1399
#, no-wrap
msgid ""
"        Order order = new Order();\n"
"        order.setProduct(\"coffee\");\n"
"        order.setName(\"Coffee lover\");\n"
"        order.setOrderId(\"1234\");\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1401
#, no-wrap
msgid "        orders.send(order);  // <4>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1403
#, no-wrap
msgid "        await().<List<? extends Message<Beverage>>>until(queue::received, t -> t.size() == 1); // <5>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1410
#, no-wrap
msgid ""
"        Beverage queuedBeverage = queue.received().get(0).getPayload();\n"
"        Assertions.assertEquals(Beverage.State.READY, queuedBeverage.getPreparationState());\n"
"        Assertions.assertEquals(\"coffee\", queuedBeverage.getBeverage());\n"
"        Assertions.assertEquals(\"Coffee lover\", queuedBeverage.getCustomer());\n"
"        Assertions.assertEquals(\"1234\", queuedBeverage.getOrderId());\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1414
msgid "Inject the in-memory connector in your test class."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1415
msgid "Retrieve the incoming channel (`orders`) - the channel must have been switched to in-memory in the test resource."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1416
msgid "Retrieve the outgoing channel (`queue`) - the channel must have been switched to in-memory in the test resource."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1417
msgid "Use the `send` method to send a message to the `orders` channel. So, the application will process this message."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1418
msgid "Use the `received` method to check the messages produced by the application."
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1419
#, no-wrap
msgid "Starting Kafka in a test resource"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1423
msgid "Alternatively, you can start a Kafka broker in a test resource.  The following snippet shows a test resource starting a Kafka broker using https://www.testcontainers.org/modules/kafka/[Testcontainers]:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1427
#, no-wrap
msgid "public class KafkaResource implements QuarkusTestResourceLifecycleManager {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1429
#, no-wrap
msgid "    private final KafkaContainer kafka = new KafkaContainer();\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1435
#, no-wrap
msgid ""
"    @Override\n"
"    public Map<String, String> start() {\n"
"        kafka.start();\n"
"        return Collections.singletonMap(\"kafka.bootstrap.servers\", kafka.getBootstrapServers());  // <1>\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1441
#, no-wrap
msgid ""
"    @Override\n"
"    public void stop() {\n"
"        kafka.close();\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1443
msgid "Configure the Kafka bootstrap location, so the application connects to this broker."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1447
#, no-wrap
msgid "Kubernetes Service Bindings"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1452
msgid "Quarkus Kafka extension supports link:deploying-to-kubernetes.adoc[Service Binding Specification for Kubernetes].  You can enable this by adding the `quarkus-kubernetes-service-binding` extension to your application."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1454
msgid "When running in appropriately configured Kubernetes clusters, Kafka extension will pull its Kafka broker connection configuration from the service binding available inside the cluster, without the need for user configuration."
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1456
#, no-wrap
msgid "Configuration Reference"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1460
msgid "More details about the SmallRye Reactive Messaging configuration can be found in the https://smallrye.io/smallrye-reactive-messaging/smallrye-reactive-messaging/2.8/kafka/kafka.html[SmallRye Reactive Messaging - Kafka Connector Documentation].  The most important attributes are listed in the tables below:"
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1461
#, no-wrap
msgid "Incoming channel configuration (polling from Kafka)"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1464
#: upstream/_versions/main/guides/kafka.adoc:1618
msgid "The following attributes are configured using:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1468
#, no-wrap
msgid "mp.messaging.incoming.your-channel-name.attribute=value\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1471
#: upstream/_versions/main/guides/kafka.adoc:1626
msgid "Some properties have aliases which can be configured globally:"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1475
#: upstream/_versions/main/guides/kafka.adoc:1630
#, no-wrap
msgid "kafka.bootstrap.servers=...\n"
msgstr ""

#. type: Block title
#: upstream/_versions/main/guides/kafka.adoc:1477
#, no-wrap
msgid "Incoming Attributes of the 'smallrye-kafka' connector"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1480
#: upstream/_versions/main/guides/kafka.adoc:1635
#, no-wrap
msgid "Attribute (_alias_)"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1480
#: upstream/_versions/main/guides/kafka.adoc:1635
#, no-wrap
msgid "Description"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1480
#: upstream/_versions/main/guides/kafka.adoc:1635
#, no-wrap
msgid "Mandatory"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1482
#: upstream/_versions/main/guides/kafka.adoc:1637
#, no-wrap
msgid "Default"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1484
#: upstream/_versions/main/guides/kafka.adoc:1643
#, no-wrap
msgid ""
"*bootstrap.servers*\n"
"\n"
"_(kafka.bootstrap.servers)_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1486
#: upstream/_versions/main/guides/kafka.adoc:1645
#, no-wrap
msgid ""
"A comma-separated list of host:port to use for establishing the initial connection to the Kafka cluster.\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1486
#: upstream/_versions/main/guides/kafka.adoc:1490
#: upstream/_versions/main/guides/kafka.adoc:1494
#: upstream/_versions/main/guides/kafka.adoc:1498
#: upstream/_versions/main/guides/kafka.adoc:1502
#: upstream/_versions/main/guides/kafka.adoc:1506
#: upstream/_versions/main/guides/kafka.adoc:1510
#: upstream/_versions/main/guides/kafka.adoc:1514
#: upstream/_versions/main/guides/kafka.adoc:1518
#: upstream/_versions/main/guides/kafka.adoc:1522
#: upstream/_versions/main/guides/kafka.adoc:1526
#: upstream/_versions/main/guides/kafka.adoc:1534
#: upstream/_versions/main/guides/kafka.adoc:1543
#: upstream/_versions/main/guides/kafka.adoc:1547
#: upstream/_versions/main/guides/kafka.adoc:1551
#: upstream/_versions/main/guides/kafka.adoc:1555
#: upstream/_versions/main/guides/kafka.adoc:1559
#: upstream/_versions/main/guides/kafka.adoc:1563
#: upstream/_versions/main/guides/kafka.adoc:1567
#: upstream/_versions/main/guides/kafka.adoc:1571
#: upstream/_versions/main/guides/kafka.adoc:1575
#: upstream/_versions/main/guides/kafka.adoc:1579
#: upstream/_versions/main/guides/kafka.adoc:1583
#: upstream/_versions/main/guides/kafka.adoc:1587
#: upstream/_versions/main/guides/kafka.adoc:1591
#: upstream/_versions/main/guides/kafka.adoc:1595
#: upstream/_versions/main/guides/kafka.adoc:1599
#: upstream/_versions/main/guides/kafka.adoc:1603
#: upstream/_versions/main/guides/kafka.adoc:1607
#: upstream/_versions/main/guides/kafka.adoc:1611
#: upstream/_versions/main/guides/kafka.adoc:1639
#: upstream/_versions/main/guides/kafka.adoc:1645
#: upstream/_versions/main/guides/kafka.adoc:1649
#: upstream/_versions/main/guides/kafka.adoc:1653
#: upstream/_versions/main/guides/kafka.adoc:1657
#: upstream/_versions/main/guides/kafka.adoc:1663
#: upstream/_versions/main/guides/kafka.adoc:1669
#: upstream/_versions/main/guides/kafka.adoc:1675
#: upstream/_versions/main/guides/kafka.adoc:1679
#: upstream/_versions/main/guides/kafka.adoc:1685
#: upstream/_versions/main/guides/kafka.adoc:1691
#: upstream/_versions/main/guides/kafka.adoc:1697
#: upstream/_versions/main/guides/kafka.adoc:1701
#: upstream/_versions/main/guides/kafka.adoc:1705
#: upstream/_versions/main/guides/kafka.adoc:1709
#: upstream/_versions/main/guides/kafka.adoc:1713
#: upstream/_versions/main/guides/kafka.adoc:1717
#: upstream/_versions/main/guides/kafka.adoc:1721
#: upstream/_versions/main/guides/kafka.adoc:1725
#: upstream/_versions/main/guides/kafka.adoc:1729
#: upstream/_versions/main/guides/kafka.adoc:1733
#: upstream/_versions/main/guides/kafka.adoc:1737
#: upstream/_versions/main/guides/kafka.adoc:1741
#: upstream/_versions/main/guides/kafka.adoc:1745
#: upstream/_versions/main/guides/kafka.adoc:1753
#, no-wrap
msgid "false"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1488
#: upstream/_versions/main/guides/kafka.adoc:1647
#, no-wrap
msgid "`localhost:9092`"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1488
#: upstream/_versions/main/guides/kafka.adoc:1739
#, no-wrap
msgid "*topic*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1490
#: upstream/_versions/main/guides/kafka.adoc:1741
#, no-wrap
msgid ""
"The consumed / populated Kafka topic. If neither this property nor the `topics` properties are set, the channel name is used\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1492
#: upstream/_versions/main/guides/kafka.adoc:1699
#, no-wrap
msgid "*health-enabled*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1494
#: upstream/_versions/main/guides/kafka.adoc:1701
#, no-wrap
msgid ""
"Whether health reporting is enabled (default) or disabled\n"
"\n"
"Type: _boolean_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1496
#: upstream/_versions/main/guides/kafka.adoc:1500
#: upstream/_versions/main/guides/kafka.adoc:1512
#: upstream/_versions/main/guides/kafka.adoc:1516
#: upstream/_versions/main/guides/kafka.adoc:1553
#: upstream/_versions/main/guides/kafka.adoc:1613
#: upstream/_versions/main/guides/kafka.adoc:1659
#: upstream/_versions/main/guides/kafka.adoc:1677
#: upstream/_versions/main/guides/kafka.adoc:1703
#: upstream/_versions/main/guides/kafka.adoc:1707
#: upstream/_versions/main/guides/kafka.adoc:1747
#: upstream/_versions/main/guides/kafka.adoc:1755
#, no-wrap
msgid "`true`"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1496
#: upstream/_versions/main/guides/kafka.adoc:1703
#, no-wrap
msgid "*health-readiness-enabled*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1498
#: upstream/_versions/main/guides/kafka.adoc:1705
#, no-wrap
msgid ""
"Whether readiness health reporting is enabled (default) or disabled\n"
"\n"
"Type: _boolean_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1500
#: upstream/_versions/main/guides/kafka.adoc:1711
#, no-wrap
msgid "*health-readiness-topic-verification*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1502
#: upstream/_versions/main/guides/kafka.adoc:1713
#, no-wrap
msgid ""
"Whether the readiness check should verify that topics exist on the broker. Default to false. Enabling it requires an admin connection.\n"
"\n"
"Type: _boolean_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1504
#: upstream/_versions/main/guides/kafka.adoc:1524
#: upstream/_versions/main/guides/kafka.adoc:1549
#: upstream/_versions/main/guides/kafka.adoc:1565
#: upstream/_versions/main/guides/kafka.adoc:1715
#: upstream/_versions/main/guides/kafka.adoc:1731
#, no-wrap
msgid "`false`"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1504
#: upstream/_versions/main/guides/kafka.adoc:1707
#, no-wrap
msgid "*health-readiness-timeout*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1506
#: upstream/_versions/main/guides/kafka.adoc:1709
#, no-wrap
msgid ""
"During the readiness health check, the connector connects to the broker and retrieves the list of topics. This attribute specifies the maximum duration (in ms) for the retrieval. If exceeded, the channel is considered not-ready.\n"
"\n"
"Type: _long_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1508
#: upstream/_versions/main/guides/kafka.adoc:1711
#, no-wrap
msgid "`2000`"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1508
#: upstream/_versions/main/guides/kafka.adoc:1743
#, no-wrap
msgid "*tracing-enabled*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1510
#: upstream/_versions/main/guides/kafka.adoc:1745
#, no-wrap
msgid ""
"Whether tracing is enabled (default) or disabled\n"
"\n"
"Type: _boolean_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1512
#: upstream/_versions/main/guides/kafka.adoc:1655
#, no-wrap
msgid "*cloud-events*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1514
#: upstream/_versions/main/guides/kafka.adoc:1657
#, no-wrap
msgid ""
"Enables (default) or disables the Cloud Event support. If enabled on an _incoming_ channel, the connector analyzes the incoming records and try to create Cloud Event metadata. If enabled on an _outgoing_, the connector sends the outgoing messages as Cloud Event if the message includes Cloud Event Metadata.\n"
"\n"
"Type: _boolean_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1516
#, no-wrap
msgid "*topics*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1518
#, no-wrap
msgid ""
"A comma-separating list of topics to be consumed. Cannot be used with the `topic` or `pattern` properties\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1520
#, no-wrap
msgid "*pattern*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1522
#, no-wrap
msgid ""
"Indicate that the `topic` property is a regular expression. Must be used with the `topic` property. Cannot be used with the `topics` property\n"
"\n"
"Type: _boolean_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1524
#, no-wrap
msgid "*key.deserializer*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1526
#, no-wrap
msgid ""
"The deserializer classname used to deserialize the record's key\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1528
#, no-wrap
msgid "`org.apache.kafka.common.serialization.StringDeserializer`"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1528
#, no-wrap
msgid "*value.deserializer*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1530
#, no-wrap
msgid ""
"The deserializer classname used to deserialize the record's value\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1530
#: upstream/_versions/main/guides/kafka.adoc:1749
#, no-wrap
msgid "true"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1532
#, no-wrap
msgid "*fetch.min.bytes*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1534
#, no-wrap
msgid ""
"The minimum amount of data the server should return for a fetch request. The default setting of 1 byte means that fetch requests are answered as soon as a single byte of data is available or the fetch request times out waiting for data to arrive.\n"
"\n"
"Type: _int_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1536
#: upstream/_versions/main/guides/kafka.adoc:1597
#: upstream/_versions/main/guides/kafka.adoc:1641
#, no-wrap
msgid "`1`"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1536
#, no-wrap
msgid "*group.id*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1543
#, no-wrap
msgid ""
"A unique string that identifies the consumer group the application belongs to.\n"
"\n"
"If not set, defaults to the application name as set by the `quarkus.application.name` configuration property.\n"
"\n"
"If that is not set either, a unique, generated id is used.\n"
"It is recommended to always define a `group.id`, the automatic generation is only a convenient feature for development.\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1545
#, no-wrap
msgid "*enable.auto.commit*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1547
#, no-wrap
msgid ""
"If enabled, consumer's offset will be periodically committed in the background by the underlying Kafka client, ignoring the actual processing outcome of the records. It is recommended to NOT enable this setting and let Reactive Messaging handles the commit.\n"
"\n"
"Type: _boolean_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1549
#, no-wrap
msgid "*retry*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1551
#, no-wrap
msgid ""
"Whether or not the connection to the broker is re-attempted in case of failure\n"
"\n"
"Type: _boolean_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1553
#, no-wrap
msgid "*retry-attempts*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1555
#, no-wrap
msgid ""
"The maximum number of reconnection before failing. -1 means infinite retry\n"
"\n"
"Type: _int_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1557
#: upstream/_versions/main/guides/kafka.adoc:1735
#, no-wrap
msgid "`-1`"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1557
#, no-wrap
msgid "*retry-max-wait*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1559
#, no-wrap
msgid ""
"The max delay (in seconds) between 2 reconnects\n"
"\n"
"Type: _int_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1561
#, no-wrap
msgid "`30`"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1561
#, no-wrap
msgid "*broadcast*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1563
#, no-wrap
msgid ""
"Whether the Kafka records should be dispatched to multiple consumer\n"
"\n"
"Type: _boolean_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1565
#, no-wrap
msgid "*auto.offset.reset*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1567
#, no-wrap
msgid ""
"What to do when there is no initial offset in Kafka.Accepted values are earliest, latest and none\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1569
#, no-wrap
msgid "`latest`"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1569
#, no-wrap
msgid "*failure-strategy*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1571
#, no-wrap
msgid ""
"Specify the failure strategy to apply when a message produced from a record is acknowledged negatively (nack). Values can be `fail` (default), `ignore`, or `dead-letter-queue`\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1573
#, no-wrap
msgid "`fail`"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1573
#, no-wrap
msgid "*commit-strategy*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1575
#, no-wrap
msgid ""
"Specify the commit strategy to apply when a message produced from a record is acknowledged. Values can be `latest`, `ignore` or `throttled`. If `enable.auto.commit` is true then the default is `ignore` otherwise it is `throttled`\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1577
#, no-wrap
msgid "*throttled.unprocessed-record-max-age.ms*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1579
#, no-wrap
msgid ""
"While using the `throttled` commit-strategy, specify the max age in milliseconds that an unprocessed message can be before the connector is marked as unhealthy.\n"
"\n"
"Type: _int_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1581
#, no-wrap
msgid "`60000`"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1581
#, no-wrap
msgid "*dead-letter-queue.topic*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1583
#, no-wrap
msgid ""
"When the `failure-strategy` is set to `dead-letter-queue` indicates on which topic the record is sent. Defaults is `dead-letter-topic-$channel`\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1585
#, no-wrap
msgid "*dead-letter-queue.key.serializer*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1587
#, no-wrap
msgid ""
"When the `failure-strategy` is set to `dead-letter-queue` indicates the key serializer to use. If not set the serializer associated to the key deserializer is used\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1589
#, no-wrap
msgid "*dead-letter-queue.value.serializer*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1591
#, no-wrap
msgid ""
"When the `failure-strategy` is set to `dead-letter-queue` indicates the value serializer to use. If not set the serializer associated to the value deserializer is used\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1593
#, no-wrap
msgid "*partitions*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1595
#, no-wrap
msgid ""
"The number of partitions to be consumed concurrently. The connector creates the specified amount of Kafka consumers. It should match the number of partition of the targeted topic\n"
"\n"
"Type: _int_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1597
#, no-wrap
msgid "*consumer-rebalance-listener.name*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1599
#, no-wrap
msgid ""
"The name set in `javax.inject.Named` of a bean that implements `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener`. If set, this rebalance listener is applied to the consumer.\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1601
#, no-wrap
msgid "*key-deserialization-failure-handler*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1603
#, no-wrap
msgid ""
"The name set in `javax.inject.Named` of a bean that implements `io.smallrye.reactive.messaging.kafka.DeserializationFailureHandler`. If set, deserialization failure happening when deserializing keys are delegated to this handler which may provide a fallback value.\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1605
#, no-wrap
msgid "*value-deserialization-failure-handler*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1607
#, no-wrap
msgid ""
"The name set in `javax.inject.Named` of a bean that implements `io.smallrye.reactive.messaging.kafka.DeserializationFailureHandler`. If set, deserialization failure happening when deserializing values are delegated to this handler which may provide a fallback value.\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1609
#, no-wrap
msgid "*graceful-shutdown*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1611
#, no-wrap
msgid ""
"Whether or not a graceful shutdown should be attempted when the application terminates.\n"
"\n"
"Type: _boolean_"
msgstr ""

#. type: Title ===
#: upstream/_versions/main/guides/kafka.adoc:1615
#, no-wrap
msgid "Outgoing channel configuration (writing to Kafka)"
msgstr ""

#. type: delimited block -
#: upstream/_versions/main/guides/kafka.adoc:1623
#, no-wrap
msgid "mp.messaging.outgoing.your-channel-name.attribute=value\n"
msgstr ""

#. type: Block title
#: upstream/_versions/main/guides/kafka.adoc:1632
#, no-wrap
msgid "Outgoing Attributes of the 'smallrye-kafka' connector"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1637
#, no-wrap
msgid "*acks*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1639
#, no-wrap
msgid ""
"The number of acknowledgments the producer requires the leader to have received before considering a request complete. This controls the durability of records that are sent. Accepted values are: 0, 1, all\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1647
#, no-wrap
msgid "*buffer.memory*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1649
#, no-wrap
msgid ""
"The total bytes of memory the producer can use to buffer records waiting to be sent to the server.\n"
"\n"
"Type: _long_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1651
#, no-wrap
msgid "`33554432`"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1651
#, no-wrap
msgid "*close-timeout*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1653
#, no-wrap
msgid ""
"The amount of milliseconds waiting for a graceful shutdown of the Kafka producer\n"
"\n"
"Type: _int_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1655
#, no-wrap
msgid "`10000`"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1661
#, no-wrap
msgid ""
"*cloud-events-data-content-type*\n"
"\n"
"_(cloud-events-default-data-content-type)_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1663
#, no-wrap
msgid ""
"Configure the default `datacontenttype` attribute of the outgoing Cloud Event. Requires `cloud-events` to be set to `true`. This value is used if the message does not configure the `datacontenttype` attribute itself\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1667
#, no-wrap
msgid ""
"*cloud-events-data-schema*\n"
"\n"
"_(cloud-events-default-data-schema)_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1669
#, no-wrap
msgid ""
"Configure the default `dataschema` attribute of the outgoing Cloud Event. Requires `cloud-events` to be set to `true`. This value is used if the message does not configure the `dataschema` attribute itself\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1673
#, no-wrap
msgid ""
"*cloud-events-insert-timestamp*\n"
"\n"
"_(cloud-events-default-timestamp)_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1675
#, no-wrap
msgid ""
"Whether or not the connector should insert automatically the `time` attribute` into the outgoing Cloud Event. Requires `cloud-events` to be set to `true`. This value is used if the message does not configure the `time` attribute itself\n"
"\n"
"Type: _boolean_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1677
#, no-wrap
msgid "*cloud-events-mode*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1679
#, no-wrap
msgid ""
"The Cloud Event mode (`structured` or `binary` (default)). Indicates how are written the cloud events in the outgoing record\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1681
#, no-wrap
msgid "`binary`"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1683
#, no-wrap
msgid ""
"*cloud-events-source*\n"
"\n"
"_(cloud-events-default-source)_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1685
#, no-wrap
msgid ""
"Configure the default `source` attribute of the outgoing Cloud Event. Requires `cloud-events` to be set to `true`. This value is used if the message does not configure the `source` attribute itself\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1689
#, no-wrap
msgid ""
"*cloud-events-subject*\n"
"\n"
"_(cloud-events-default-subject)_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1691
#, no-wrap
msgid ""
"Configure the default `subject` attribute of the outgoing Cloud Event. Requires `cloud-events` to be set to `true`. This value is used if the message does not configure the `subject` attribute itself\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1695
#, no-wrap
msgid ""
"*cloud-events-type*\n"
"\n"
"_(cloud-events-default-type)_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1697
#, no-wrap
msgid ""
"Configure the default `type` attribute of the outgoing Cloud Event. Requires `cloud-events` to be set to `true`. This value is used if the message does not configure the `type` attribute itself\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1715
#, no-wrap
msgid "*key*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1717
#, no-wrap
msgid ""
"A key to used when writing the record\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1719
#, no-wrap
msgid "*key.serializer*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1721
#, no-wrap
msgid ""
"The serializer classname used to serialize the record's key\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1723
#, no-wrap
msgid "`org.apache.kafka.common.serialization.StringSerializer`"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1723
#, no-wrap
msgid "*max-inflight-messages*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1725
#, no-wrap
msgid ""
"The maximum number of messages to be written to Kafka concurrently. It limits the number of messages waiting to be written and acknowledged by the broker. You can set this attribute to `0` remove the limit\n"
"\n"
"Type: _long_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1727
#, no-wrap
msgid "`1024`"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1727
#, no-wrap
msgid "*merge*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1729
#, no-wrap
msgid ""
"Whether the connector should allow multiple upstreams\n"
"\n"
"Type: _boolean_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1731
#, no-wrap
msgid "*partition*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1733
#, no-wrap
msgid ""
"The target partition id. -1 to let the client determine the partition\n"
"\n"
"Type: _int_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1735
#, no-wrap
msgid "*retries*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1737
#, no-wrap
msgid ""
"Setting a value greater than zero will cause the client to resend any record whose send fails with a potentially transient error.\n"
"\n"
"Type: _long_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1739
#, no-wrap
msgid "`2147483647`"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1747
#, no-wrap
msgid "*value.serializer*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1749
#, no-wrap
msgid ""
"The serializer classname used to serialize the payload\n"
"\n"
"Type: _string_"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1751
#, no-wrap
msgid "*waitForWriteCompletion*"
msgstr ""

#. type: Table
#: upstream/_versions/main/guides/kafka.adoc:1753
#, no-wrap
msgid ""
"Whether the client waits for Kafka to acknowledge the written record before acknowledging the message\n"
"\n"
"Type: _boolean_"
msgstr ""

#. type: Title ==
#: upstream/_versions/main/guides/kafka.adoc:1757
#, no-wrap
msgid "Going further"
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1761
msgid "This guide has shown how you can interact with Kafka using Quarkus.  It utilizes SmallRye Reactive Messaging to build data streaming applications."
msgstr ""

#. type: Plain text
#: upstream/_versions/main/guides/kafka.adoc:1762
msgid "If you want to go further check the documentation of https://smallrye.io/smallrye-reactive-messaging[SmallRye Reactive Messaging], the implementation used in Quarkus."
msgstr ""
